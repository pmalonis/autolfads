%% Generate synthetic Lorenz datasets

% build the dataset collection
datasetPath = '~/lorenz_example/datasets1';

% generate demo datasets
if ~exist(fullfile(datasetPath, 'dataset001_large.mat'), 'file')
    LFADS.Utils.generateDemoDatasets(datasetPath);
end

%% Locate and specify the datasets
dc = PBTExperiment.DatasetCollection(datasetPath);
dc.name = 'lorenz_example';

% add individual datasets
PBTExperiment.Dataset(dc, 'dataset001_large.mat');
%MyExperiment.Dataset(dc, 'dataset002.mat');
%MyExperiment.Dataset(dc, 'dataset003.mat');

% load metadata from the datasets to populate the dataset collection
dc.loadInfo;

%% Build RunCollection
% Run a single model for each dataset, and one stitched run with all datasets

runRoot = '~/lorenz_example/pbt_test2';
rc = PBTExperiment.RunCollection(runRoot, 'exampleRun', dc);

% replace this with the date this script was authored as YYYYMMDD 
% This ensures that updates to lfads-run-manager won't invalidate older 
% runs already on disk and provides for backwards compatibility
rc.version = 20180109;

%% Set parameters for the entire run collection

par = PBTExperiment.RunParams;
par.doPBT = true;
par.PBTscript = '/snel/home/mreza/projects/PBT_HP_opt/PBT_HP_opt/pbt_opt/pbt_script_run_manager.py';
par.spikeBinMs = 5; % rebin the data at 2 ms
par.c_co_dim = 0; % no controller --> no inputs to generator
par.c_batch_size = 150; % must be < 1/5 of the min trial count
par.c_factors_dim = 8; % and manually set it for multisession stitched models
par.useAlignmentMatrix = false; % use alignment matrices initial guess for multisession stitching

par.c_gen_dim = 64; % number of units in generator RNN
par.c_ic_enc_dim = 64; % number of units in encoder RNN

par.c_learning_rate_stop = 1e-3; % we can stop really early for the demo

% add a single set of parameters to this run collection. Additional
% parameters can be added. LFADS.RunParams is a value class, unlike the other objects
% which are handle classes, so you can modify par freely.
rc.addParams(par);

%% Add RunSpecs

% Run a single model for each dataset, and one stitched run with all datasets

% add each individual run
for iR = 1:dc.nDatasets
    runSpec = PBTExperiment.RunSpec(dc.datasets(iR).getSingleRunName(), dc, dc.datasets(iR).name);
    rc.addRunSpec(runSpec);
end

% add the final stitching run with all datasets
rc.addRunSpec(PBTExperiment.RunSpec('all', dc, 1:dc.nDatasets));

% adding a return here allows you to call this script to recreate all of
% the objects here for subsequent analysis after the actual LFADS models
% have been trained. The code below will setup the LFADS runs in the first
% place.

return;

%% Prepare LFADS input

% generate all of the data files LFADS needs to run everything
rc.prepareForLFADS();

% write a python script that will train all of the LFADS runs using a
% load-balancer against the available CPUs and GPUs
%rc.writeShellScriptRunQueue('display', 50, 'maxTasksSimultaneously', 4, 'gpuList', [0 1]);

%% writes the shell script to run PBT



%% after the run ends, load posterior samples

rc.runs(1).loadPosteriorMeans
 
seq = rc.runs(1).addPosteriorMeansToSeq;
imagesc(seq{1}(1).factors)

